{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import progressbar as pgb\n",
    "import csv\n",
    "import random\n",
    "import os, sys\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters of the model.\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_float('learning_rate', 0.004, '')\n",
    "flags.DEFINE_integer('feature_num', 3, '')\n",
    "flags.DEFINE_integer('batch_size', 1, '')\n",
    "flags.DEFINE_integer('max_steps', 1, '')\n",
    "flags.DEFINE_boolean('dropout', False, '')\n",
    "flags.DEFINE_integer('eval_every', 5, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_humanbase_coex_data(file_name):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    target_file = open(file_name, 'r')\n",
    "    target_raws = target_file.readlines()\n",
    "    print(\"Reading coexpression data {}. . . .\".format(file_name))\n",
    "    target_list = list(map(lambda x : x.rstrip().split('\\t') , target_raws))\n",
    "    \n",
    "    print(\"Edge building . . . . .\")\n",
    "    coex_graph = nx.Graph()\n",
    "    bar = pgb.ProgressBar(max_value=len(target_raws))\n",
    "    prog = 0\n",
    "    for i in target_list:\n",
    "        try:\n",
    "            coex_graph.add_edge(i[0], i[1], weight=float(i[2]))\n",
    "        except:\n",
    "            print(\"{} is not valid float\".format(i[2]))\n",
    "        prog += 1\n",
    "        bar.update(prog)\n",
    "    \n",
    "    return coex_graph\n",
    "\n",
    "\n",
    "def update_features_coex(file_name, coex_graph):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    genes = pd.read_csv(file_name)\n",
    "    disease_name = file_name.rsplit('/')[1].split('_')[0]\n",
    "    \n",
    "    print(\"Update features from {}. . .\".format(file_name))\n",
    "    bar = pgb.ProgressBar(max_value=len(coex_graph.nodes))\n",
    "    prog = 0\n",
    "    for v in coex_graph.nodes:\n",
    "        check_in = False\n",
    "        for i in range(len(genes)):\n",
    "            if str(v) == str(genes['geneid'].iloc[i]):\n",
    "                nx.set_node_attributes(coex_graph, {v :{disease_name : float(genes['score'].iloc[i])}})\n",
    "                check_in = True\n",
    "                break\n",
    "        if not check_in:\n",
    "            nx.set_node_attributes(coex_graph, {v :{disease_name : 0.0}})\n",
    "            check_in = False\n",
    "        prog += 1\n",
    "        bar.update(prog)\n",
    "    \n",
    "    return coex_graph\n",
    "\n",
    "\n",
    "def visualize_network(net, edge_width_scale=1):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    pos = nx.spring_layout(net)\n",
    "    \n",
    "    weight_list = []\n",
    "    for node1, node2, data in net.edges(data=True):\n",
    "        weight_list.append(data['weight'])\n",
    "    weight_set = set(weight_list)\n",
    "\n",
    "    for w in weight_set:\n",
    "        weighted_edges = [(node1, node2) for (node1, node2, edge_attr) in net.edges(data=True) if edge_attr['weight']==w]\n",
    "        width = edge_width_scale*w*len(net)/sum(weight_set)\n",
    "        nx.draw_networkx_edges(net, pos, edge_list=weighted_edges, width=width)\n",
    "    nx.draw_networkx_nodes(net, pos, node_list=net.nodes(), node_size=20)\n",
    "    \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading coexpression data data/tooth_top_0.15. . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (81398 of 9369607) |                | Elapsed Time: 0:00:00 ETA:   0:00:22"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge building . . . . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (9369607 of 9369607) |##############| Elapsed Time: 0:00:23 ETA:  00:00:00"
     ]
    }
   ],
   "source": [
    "### Make graph with coexpression data\n",
    "coex_graph = load_humanbase_coex_data(\"data/tooth_top_0.15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% (51 of 22684) |                     | Elapsed Time: 0:00:00 ETA:   0:00:45"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update features from data/Periodontitis_genes.csv. . .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6% (1524 of 22684) |#                  | Elapsed Time: 0:00:02 ETA:   0:00:40"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b2aa92fb1a12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Give score features that represent relations with a disease for each vertex.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcoex_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_features_coex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/Periodontitis_genes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoex_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcoex_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_features_coex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/diabetes_genes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoex_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcoex_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_features_coex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/rheumatoid_genes.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoex_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-88f6bd65399e>\u001b[0m in \u001b[0;36mupdate_features_coex\u001b[0;34m(file_name, coex_graph)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mcheck_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geneid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_node_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoex_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mdisease_name\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mcheck_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   2213\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Give score features that represent relations with a disease for each vertex.\n",
    "coex_graph = update_features_coex(\"data/Periodontitis_genes.csv\", coex_graph)\n",
    "coex_graph = update_features_coex(\"data/diabetes_genes.csv\", coex_graph)\n",
    "coex_graph = update_features_coex(\"data/rheumatoid_genes.csv\", coex_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1671 entries, 0 to 1670\n",
      "Data columns (total 18 columns):\n",
      "Disease           1671 non-null object\n",
      "Disease_id        1671 non-null object\n",
      "Gene              1671 non-null object\n",
      "geneid            1671 non-null int64\n",
      "UniProt           1527 non-null object\n",
      "Gene_Full_Name    1671 non-null object\n",
      "Protein_Class     820 non-null object\n",
      "N_diseases_g      1671 non-null int64\n",
      "DSI_g             1671 non-null float64\n",
      "DPI_g             1671 non-null float64\n",
      "pLI               1482 non-null float64\n",
      "score             1671 non-null float64\n",
      "EL_gda            1671 non-null object\n",
      "EI_gda            1395 non-null float64\n",
      "N_PMIDs           1671 non-null int64\n",
      "N_SNPs_gda        1671 non-null int64\n",
      "First_Ref         1650 non-null float64\n",
      "Last_Ref          1650 non-null float64\n",
      "dtypes: float64(7), int64(4), object(7)\n",
      "memory usage: 235.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"data/diabetes_genes.csv\")\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (22684,) for Tensor 'vertex_input:0', which has shape '(22684, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3ddd0ac01bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m                   \u001b[0mGCN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                   is_train_step:True}\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mGCN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGCN_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m                              \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[0;32m-> 1128\u001b[0;31m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1129\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (22684,) for Tensor 'vertex_input:0', which has shape '(22684, 1)'"
     ]
    }
   ],
   "source": [
    "#### Tensorflow Session and training.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "LOG_DIR = os.path.join(os.path.dirname(os.path.abspath('')), 'tensorLog')\n",
    "\n",
    "if os.path.exists(LOG_DIR) == False:\n",
    "    os.mkdir(LOG_DIR)\n",
    "else:\n",
    "    shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
    "    os.mkdir(LOG_DIR)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(LOG_DIR, graph=sess.graph)\n",
    "\n",
    "GCN_model = graph_cnn(coex_graph, \"coex_periodontitis\")\n",
    "is_train_step = tf.placeholder(tf.bool)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(GCN_model.loss)\n",
    "\n",
    "GCN_model.vertex_inputs = GCN_model.reshape(GCN_model.X.shape)\n",
    "GCN_model.vertex_labels = GCN_model.reshape(GCN_model.Y.shape)\n",
    "\n",
    "for epoch in range(iterations):\n",
    "    train_dict = {GCN_model.X: GCN_model.vertex_inputs,\n",
    "                  GCN_model.Y: GCN_model.vertex_labels,\n",
    "                  GCN_model.loss_weight: 1,\n",
    "                  GCN_model.dropout:0.8,\n",
    "                  is_train_step:True}\n",
    "    summary, _ = sess.run([merged, train_step], feed_dict=train_dict)\n",
    "    \n",
    "    train_loss, train_preds = sess.run([GCN_model.loss, GCN_model.model_output()], feed_dict=train_dict)\n",
    "    \n",
    "    writer.add_summary(summary, epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GCN_model.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22684,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.fromiter(dict(coex_graph.nodes(data='score')).values(), float).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### CHECK CONNECTED COMPONENTS OF COEX_GRAPH\n",
    "nx.algorithms.number_connected_components(coex_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.757113  ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        , 46.08880127,  1.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        , 39.44476557, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  2.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [ 1.        ,  1.        ,  1.        , ...,  1.        ,\n",
       "         1.        ,  2.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(np.sqrt(np.fromiter(dict(coex_graph.degree).values(), float))) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv('diabetes_genes.csv')\n",
    "\n",
    "genes = genes.drop(genes.index([[10]], axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(coex_graph, {'1': {'a':3, 'b':4}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_list = list(coex_graph.nodes())\n",
    "#for n in node_list:\n",
    "#    print(n,end=\"::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dict_keyiterator at 0x7f65774b1868>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.classes.function.neighbors(coex_graph,random.choice(list(coex_graph.nodes())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in coex_graph.nodes(data=True)['1'].values():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22684"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random(coex_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = open('ok.txt','w')\n",
    "a.write(\"423\\t123\\n\")\n",
    "a.write(\"423\\t123\\n\")\n",
    "a.write(\"423\\t123\\n\")\n",
    "a.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7320508075688772"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[1]][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
